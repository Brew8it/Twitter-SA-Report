%%
%% This is file `kaumasterstemplate.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% kauthesis.dtx  (with options: `masterstemplate')
%% 
%% This is a generated file.
%% 
%% Copyright (c) 2011-2014 Stefan Berthold <stefan.berthold@kau.se>
%% 
%% This file is part of the kauthesis bundle.
%% 
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%% 
%% This work has the LPPL maintenance status `author-maintained'.
%% 
%% The Current Maintainer and author of this work is Stefan Berthold.
%% 
%% This work consists of all files listed in manifest.txt.
%% 
%% kauthesis.dtx
%% Copyright (c) 2011-2015 Stefan Berthold <stefan.berthold@kau.se>

\documentclass{kaumasters} % available class options: garamond
\usepackage[swedish]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{titletoc}
\usepackage{geometry}
\usepackage{booktabs}

\usepackage{float}


\usepackage{amsmath}



%% break long URLs in references.
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
% list
\usepackage{scrextend}
\addtokomafont{labelinglabel}{\sffamily}

\usepackage{fancyhdr}

\usepackage{graphicx}
\graphicspath{{../figures/background/}}
\usepackage[numbers]{natbib}

% clickable

\renewcommand{\baselinestretch}{1.5} 

\usepackage{tabularx}


\makeatletter
\renewcommand\scriptsize{\@setfontsize\scriptsize{7}{8}}
\renewcommand\tiny{\@setfontsize\tiny{5}{6}}
\renewcommand\small{\@setfontsize\small{5}{6}}
\renewcommand\normalsize{\@setfontsize\normalsize{12}{12}}
\renewcommand\large{\@setfontsize\large{10.95}{15}}
\renewcommand\Large{\@setfontsize\Large{12}{16}}
\renewcommand\LARGE{\@setfontsize\LARGE{14.4}{18}}
\renewcommand\huge{\@setfontsize\huge{20.74}{30}}
\renewcommand\Huge{\@setfontsize\Huge{24}{36}}
\makeatother
\usepackage{sectsty}

\chapterfont{\Huge}
\sectionfont{\huge}
\subsectionfont{\LARGE}
\subsubsectionfont{\Large}
\paragraphfont{\Large}


%\pagestyle{fancy}
%\fancyhf{}
%\lhead[\texttit{}]{}
%\rhead[]{}
%\setlength{\headheight}{15pt}

\title{Twitter Sentiment Analysis}
\author{Johan Selberg, Johannes Bandgren}
\supervisor{Kerstin Andersson}
\examiner{Exam}
\institute{Department of Computer Science}
\place{Karlstad Universitet}
\begin{document}

\maketitle




\frontmatter
\begin{abstract}
  Abstract.
  \keywords keywords
\end{abstract}
\approvalpage%
\begin{acknowledgements}
  Thanks.
\end{acknowledgements}

\tableofcontents{}
\listoffigures
\listoftables
\mainmatter
% för att fucka med marginaler
%\newgeometry{top=20mm, bottom=20mm, right=30mm, left=30mm}
\pagestyle{fancy}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE,LO]{\rightmark}
\fancyfoot{}
\chapter{Introduktion}

\newpage


\chapter{Bakgrund}
Syftet med studien är att utvärdera tre stycken klassificeringsmodeller inom maskininlärning och hur bearbetningen samt märkningen av en datamängd påverkar en klassificeringsmodells prestanda. Maskininlärningsalgoritmerna som kommer att användas för att få fram klassiciferingsmodellerna är Naive Bayes (NB) och Support Vector Machine  (SVM). Den tredje klassificeringsmodellen som tas fram kommer att vara en djuplärande modell  som representeras av ett neuronnät, mer specifikt ett Convolutional neural network (CNN). Figur \ref{fig:overfig} visar en förenklad bild av hur processen för att utvärdera klassificeringsmodellerna kommer att se ut. Datamängden består av en mängd indata som är märkt med förväntad utdata, som går igenom en bearbetningsprocess där t.ex. data som inte tillför något värde tas bort och där mängden av data delas upp i tränings- och valideringsdata.  Bearbetningsprocessen diskuteras mer ingående i \ref{exp:pre}. På den bearbetade datan utförs ett särdragsurval, där dataspecifika särdrag plockas ut…MER .. som diskuteras vidare i \ref{exp:feat}. Träningsmängden används av maskininlärningsalgoritmen för att skapa klassiciferingsmodellen. När klassificeringsmodellen är framtagen används valideringmängden för att utvärdera prestandan av modellen.

\begin{figure}[h]
\includegraphics[width=12cm]{oversiktsfigur}
\centering
\caption{Utvärderingsprocessen av maskininlärningsmodeller}
\label{fig:overfig}
\end{figure}

Studien kommer att använda maskininlärning för att utföra sentimentanalys (SA) d.v.s utläsa huruvida en text uttrycker någonting positivt eller negativt. Uppdragsgivaren, CGI, betraktar sentimentanalys  som en viktig pusselbit för framtida lösningar man vill erbjuda sina kunder. Lösningar skulle kunna vara chatbotar där sentimentanalys används så att chatboten ändrar sitt språk utefter svaren från slutanvändare. Eller att det kan användas för trendanalys där ett företag vill veta vad allmänheten tycker före och efter att man har släppt en ny produkt eller efter att kvartalsrapporten har släppts.

I avsnitt \ref{SA} förklaras vad SA är och olika klassificeringstekniker inom SA berskrivs kortfattat. I avsnitt \ref{ML} ges en kort introduktion till maskininlärning och framstegen som gjorts under den senaste tiden. Dessutom beskrivs NB och SVM samt hur inlärningsprocessen ser ut. I avsnitt \ref{DS} ges en överblick över hur en datamängd ser ut och vilka märkningsmetoder som används för twittersentimentanalys (TSA). Avsnittet beskriver även de valda datamängderna. I avsnitt \ref{TSA} ges en introduktion till TSA och vilka utmaning samt problem TSA har. Slutligen i avsnitt \ref{TSAev} förklaras vilka hjälpmedel som kommer att användas för att utvärdera algoritmernas prestanda.


\section{Sentimentanalys} \label{SA}
SA används för att studera människors åsikter, attityder och känslor mot olika entiteter. En entitet kan vara ett ämne, en händelse eller en individ. Målet med SA är att identifiera känslan som är uttryckt i en text för att därefter analysera den. Processen delas upp i tre steg: att hitta entiteter, identifiera känslan för de entiteterna och slutligen klassificera dessa entiteter. \cite{SAsurvey}.

Inom SA appliceras klassificeringen på 3 olika nivåer: dokument-, menings- och aspektnivå \cite{SAsurvey}. SA på dokumentnivå klassificerar om ett helt dokument uttrycker en positiv eller negativ åsikt, exempel på dokument kan vara produktrecensioner eller nyhetsartiklar. Medan på meningsnivå klassificeras varje mening i ett dokument. Slutligen nere på aspektnivå analyseras de möjliga aspekterna av en entitet. En mening kan behandla olika aspekter av en entitet. Både positiva och negativa åsikter kan delges om en entitets olika aspekter. Ett exempel på det är meningen “Ölen var väldigt god, men tyvärr alldeles för dyr”, som innehåller både en positiv och en negativ åsikt om en entitet som i det här fallet är ölen.
\subsection{Klassificeringstekniker} \label{SAkt}
De olika klassificeringsteknikerna som i nuläget används för SA delas upp i 3 olika kategorier: maskininlärningsmetoder, lexikonbaserade metoder samt hybrida metoder \cite{SAsurvey}. 

Maskininlärningsmetoder använder etablerade maskininlärningsalgoritmer tillsammans med språkliga särdrag för att konstruera klassificerare som kan avgöra om en text uttrycker någonting positivt eller negativt [ref=Sentiment analysis a survey]. Prestandan för maskininlärningsmetoder är beroende av mängden träningsdata, större mängder data ger vanligtvis bättre resultat \cite{TSAsurvey}. Maskininlärningsmetoder är dessutom domänberoende, vilket gör att de inte presterar bra när de används på andra domäner än det de har tränats på. 

Lexikonbaserade metoder använder sig av ordlistor för att analysera text \cite{SAsurvey}. Ordlistorna består av positiva och negativa termer som används för att beräkna vad en given text uttrycker för sentiment.
Fördelen med lexikonbaserade metoder är att de inte kräver någon  träningsdata \cite{TSAsurvey}. Men faktumet att de är beroende av statiska ordlistor betyder att de inte tar hänsyn till termer som inte finns i ordlistorna. Det betyder att ordlistor måste uppdateras kontinuerligt för innehåll som är dynamiskt och ständigt under utveckling, vilket är särskilt problematiskt för texter som förekommer på sociala medier. 

Hybrida metoder kombinerar lexikonbaserade metoder med maskininlärningsmetoder \cite{TSAsurvey}. Genom att kombinera metoderna med varandra kan de väga upp för varandras svagheter. Nackdelen med hybrida metoder är dock att de kräver en hög beräkningskomplexitet.

Experimentet som presenteras i studien fokuserar enbart på maskininlärningsmetoder.

\section{Maskininlärning} \label{ML}
Maskininlärning är ett delområde inom artificiell intelligens (AI), där målet är att göra det möjligt för datorer att lära sig på egen hand. Maskininlärningsalgoritmer gör det möjligt att identifiera olika mönster från observerad data, bygga upp en generell modell som kan förutsäga saker utan att ha blivit förprogrammerade med explicita regler för hur den ska lösa ett problem. Under de senaste åren har stora framsteg inom maskininlärning gjorts. Exempelvis utvecklade DeepMind \cite{DMatari00} 2015 en agent som mästrade 49 st Atari-spel \cite{wiki:004}, med en klassificeringsmodell med endast pixlar och spelpoäng som indata. Under 2016 utvecklade DeepMind sin AlphaGo \cite{DMgo} agent som besegrade en av världens bästa Go spelare, Lee Sedol \cite{wiki:005} med 4-1 i matcher. Detta var ett framsteg för AI eftersom Go är ett komplext spel med $2 * 10^{170}$ möjliga drag \cite{wiki:006}.

Maskininlärning används också för att lösa vardagliga problem. I dagens mobiltelefoner finns en så kallad intelligent personlig assistent, även kallade Siri \cite{siri} och Google Assist \cite{google},  där användarna får hjälp med t.ex. “vad är det för väder idag?”, “Skicka ett meddelande till mamma att jag blir sen till middagen idag” och “Påminn mig imorgon att jag måste köpa mjölk”. Facebook använder även maskininlärning för ansiktsigenkänning \cite{facebook:001} på bilder som laddas upp, och för att rekommendera nya vänner \cite{facebook:002}. 

%\section{Övervakad och oövervakad inlärning} \label{MLvised}
Figur \ref{fig:ml} illustrerar att maskininlärning delas upp i två typer av inlärningsprocesser dvs. i övervakad eller oövervakad inlärning och deras underliggande algoritmer.
\begin{figure}[h]
\includegraphics[width=12cm]{ml}
\centering
\caption{Inlärningsprocesser för maskininlärning.}
\label{fig:ml}
\end{figure}

Oövervakad inlärning används när datamängden bara består av indata och inget förväntat resultat. Målet med oövervakad inlärning är att algoritmen själv lär sig att modellera den komplexa underliggande strukturen så att den kan lära sig mer om datan och själv komma fram till ett resultat \cite{wiki:007}. Exempelvis kan en oövervakad klusteralgoritm användas för att hitta likheter i bilder och följaktligen gruppera dem.
Övervakad inlärning används när datamängden består av både indata och dess förväntade utdata. Den övervakade algoritmen använder datamängden för att lära sig hur utdata beror på indata genom att skapa en klassificeringsmodell som används för att förutse utdata från ny indata som illustreras i figur \ref{fig:kl}. 

Övervakad inlärning kan man tänka sig som att en lärare övervakar programmets inlärningsprocess. Under inlärningsprocessen försöker algoritmen iterativt förutse utdata från datamängden och blir rättad av läraren vid fel förutsägelse \cite{learning:001}.

\begin{figure}[h]
\includegraphics[width=12cm]{klassmodell}
\centering
\caption{Klassificeringsprocess av data.}
\label{fig:kl}
\end{figure}

Övervakad inlärning kan brytas ner till klassificerings- och regressionsproblem och eftersom TSA kan kallas ett typiskt klassificeringsproblem \cite{SAsurvey}, kommer studien att använda algoritmer lämpade för klassificeringsproblem. I figur \ref{fig:ml} kan vi se några av dessa klassificeringsalgoritmer och enligt \cite{TSAsurvey} är speciellt Naive Bayes (NB) och Support Vector Machine (SVM)  bäst lämpade för TSA.

\subsection{Naive Bayes} \label{MLnb}
NB är en klassificeringsalgoritm som är baserad på Bayes theorem \cite{wiki:009} med starka (“naive”) oberoende antaganden mellan särdragen d.v.s NB förutsätter att närvaron av ett visst särdrag i en klass inte relaterar till närvaron av ett annat särdrag. 
Exempelvis kan en frukt anses vara ett äpple om det är grönt, runt och är 10 cm i diameter. Även om särdragen grönt, runt och diameter kan bero på varandra så bidrar alla särdragen självständigt till sannolikheten att frukten är ett äpple, det är därför algoritmen kallas (“naive”) \cite{nb:001}.

\subsection{Support Vector Machine} \label{MLsvm}
SVM är en övervakad maskininlärningsalgoritm som kan användas till både klassificerings- och regressionsproblem, för det mesta används SVM för klassifikationsproblem. SVM är baserat på idén att hitta ett hyperplan \cite{svm:001} som bäst delar upp datamängden i två klasser \cite{svm:003}. Givet en träningsmängd där förväntad utdata är markerad till en av två kategorier bygger SVM-algoritmen upp en klassificeringsmodell som kan användas för att förutse vilken kategori ny indata ger \cite{svm:002}. 

\subsection{Convolutional neural network}
Ett av de snabbast växande områden inom maskininlärning är djup inlärning \cite{TSAsurvey}. Begreppet djup inlärning syftar till artificiella neuronnät (ANN) som är uppbyggda med flera lager  \cite{cnn:001}. ANN är system som försöker ta efter beteende hos biologiska neuronnät för att stegvis bli bättre på att utföra en angiven uppgift genom att studera exempel \cite{wiki:015}. 

CNN är ett av de mest populära neuronnäten  \cite{cnn:001}. Det var ursprungligen framtaget för maskininlärningsproblem som rör datorseende och har tidigare påvisat imponerande resultat för bildigenkänning \cite{cnn:003, cnn:006}. Men på senare tid har det även visat sig att CNN är effektivt att använda för problem som rör sentimentanalys. Med relativt enkla CNN-modeller har imponerande resultat kunnat uppnås inom textklassificering.  I \cite{cnn:003} presenteras en enkel CNN-modell för textklassificering som påvisade goda resultat över flertalet datamängder. CNN-modellen som har använts i den här studien har utgått från den modell som Yoon Kim presenterar i \cite{cnn:003}.

\section{Datamängd} \label{DS}
En datamängd för övervakad inlärning består av en mängd in- och utdata som diskuteras i sektion \ref{ML}. Processen för hur rätt utdata (positiv/negativ) märks kan utföras på två olika sätt, antingen genom så kallad mänsklig märkning där människor markerar indata som positiv/negativ eller genom “distant supervision” där en dator märker indata som positiv/negativ utefter någon parameter. Den stora skillnaden mellan mänsklig märkning och “distant supervision” är att “distant supervision” kan generera en mycket större datamängd än mänsklig märkning men risken är större att märkningen blir felaktig \cite{TSAsurvey}. 
Som är beskrivit i sektion \ref{bac:intro} är ett delsytfte med denna studie att utvärdera hur de olika märkningsmodellerna påverkar maskininlärningsalgoritmernas precision. Det finns ett urval med publika twitterdatamängder där både mänsklig märkning och “distant supervison” används \cite{TSAsurvey}. Vi har valt att använda datamängderna Stanford Twitter Sentiment (STS) \cite{sts:001} och SemEval \cite{SemEval:001} eftersom de är de största publika datamängderna inom respektive märkningsmodell.

\subsection{SemEval} \label{DSse}
SemEval-datamängden består av 20633 tweets och är framtagen till en årlig TSA-tävling som har gått sedan 2013 \cite{SemEval:002}. 
För datamängden har mänsklig märkning tillämpats, där fem personer manuellt märker varje tweet via Amazon Mechanical Turk \cite{SemEval:003}.
I \cite{SemEval:004} beskrivs metoden för hur märkningen utförs, varje person markerar varje tweet antingen som mycket positivt, positivt, neutralt, negativt eller mycket negativt. Efter att alla tweets är märkta kartläggs alla tweets till kategorierna positivt, neutralt eller negativt utefter tre kriterier. Antingen att alla personer har märkt en tweet samma, en majoritet har märkt samma eller genom att ta ut ett medelvärde. Medelvärdet räknas ut genom att kartlägga de fem kategorierna till heltal mellan 2 och -2, medelvärdet räknas sedan ut och kartläggs till den närmsta kategorin. För SemEval-datamängden blev utfallet 2760 tweets där alla personer gjort samma märkning, 9944 tweets är där majoritet har märkt samma och för resterande 7928 tweets har medelvärdet räknats ut. 

\subsection{Stanford Twitter Sentiment} \label{DSsts}
STS-datamängden är framtagen mellan April 2009 och Juni 2009 av Alec Go, Richa Bhayani och Lei Huang. STS-datamängden är märkt med hjälp av “distant supervision” där märkningen bestäms av vilken typ av emoji \cite{wiki:010} ett twitterinlägg innehåller, exempelvis märks ett twitterinlägg positivt om det innehåller “:), :-),: ), :D, =)” och negativt om det innehåller “:(, :-(, : (“ \cite{sts:001}. 

\section{Twittersentimentanalys} \label{TSA}
TSA är den del av SA som specifikt handlar om att analysera inlägg som användare gör på Twitter. Twitter är en av de populäraste mikrobloggarna där användare kan skriva och kommunicera med varandra genom twitterinlägg. 2013 var Twitter en av de tio mest besökta sidorna på internet och 2016 uppmättes antalet aktiva användare per månad till 319 miljoner. Twitter är definierat som en mikroblogg på grund av det låga antalet tecken som är tillåtet för ett inlägg. I November 2017 fördubblades antalet tillåtna tecken från de tidigare 140 till 280 \cite{wiki:008}. 

Det finns en rad olika begrepp som kännetecknar Twitter och som är viktiga att känna till \cite{TSAsurvey}. En “tweet” är vad som tidigare nämnts ett twitterinlägg. Det är ett inlägg från en användare som är begränsat till 280 tecken, där användaren exempelvis kan delge sina åsikter i olika ämnen eller dela med sig av personliga upplevelser. En “tweet” behöver inte enbart innehålla ren text utan kan även innehålla länkar, bilder och videor. I fortsättningen av rapporten kommer en “tweet” att benämnas twitterinlägg.

När ett twitterinlägg innehåller “mentions” betyder det att andra användare nämns i inlägget. Det kan vara användbart för att exempelvis delge åsikter om andra användare eller för att öppet starta en diskussion med en nämnd användare. För att nämna en användare i ett twitterinlägg skrivs symbolen @ före användarnamnet. 

På Twitter har användare möjligheten att följa andra användare. Det betyder att användare kan följa andra användares aktivitet i deras egna twitterflöden och dela med sig av sin egen aktivitet till sina följares twitterflöden. En användare som följer en annan benämns på Twitter som en “follower”. Att följa andra är det primära tillvägagångssättet för att skapa kontakter med andra användare på Twitter. 

Användare har möjlighet att kategorisera twitterinlägg och det är vad “hashtags” används för. Genom att använda “hashtags” kan användare märka sina twitterinlägg med etiketter för att knyta inlägget till ett specifikt ämne. Användandet av hashtags gör det enkelt för användare att följa ett ämne. De behöver enbart söka på en specifik “hashtag” för att få fram alla twitterinlägg i ämnet. För att skapa en “hashtag” skrivs symbolen \# före namnet på etiketten.

Det är även möjligt att dela andra användares twitterinlägg till ens egna följare. Den funktionen kallas för “retweet” och ett sådant twitterinlägg startar vanligtvis med förkortningen RT följt av en “mention” av den ursprungliga författaren av twitterinlägget. Det kan exempelvis vara användbart för att sprida information till följare eller för att skapa en diskussion om innehållet i twitterinlägget med sina egna följare. 

När användare svarar på andras twitterinlägg benämns det som “replies” och det är till för att det ska gå att skapa konversationer, där det ska gå att urskilja vanliga twitterinlägg från svar på twitterinlägg. En användare svarar på ett twitterinlägg genom att göra en referens till den ursprungliga författaren av inlägget följt av svaret på inlägget.

Användare behöver inte göra alla sina inlägg offentliga för alla användare, de kan begränsa synligheten för deras twitterinlägg att enbart synas för deras egna följare. 

I figur \ref{fig:tweet} presenteras ett exempel på hur ett twitterinlägg kan se ut. Twitterinlägget är en “retweet som ursprungligen har skrivits av användaren johanselberg. Det innehåller en “hashtag” med etiketten exempel och en “mention” av användaren KAU. Twitterinlägget innehåller även en extern länk.

\begin{figure}[h]
\includegraphics[width=12cm]{exempeltweet}
\centering
\caption{Twitterinlägg innehållande ''hashtag'', ''mention'', ''retweet''.}
\label{fig:tweet}
\end{figure}

\subsection{Utmaningar} \label{TSAchall}
På grund av restriktionen av antalet tillåtna tecken i ett twitterinlägg innehåller majoriteten av twitterinlägg enbart en mening. Därför är det skillnad på klassificeringsnivåerna i TSA och SA. I TSA är det ingen skillnad på dokument- och meningsnivå. Därför används det enbart två klassificeringsnivåer inom TSA: meningsnivå (meddelandenivå) och aspektnivå. \cite{TSAsurvey}

Restriktionen av antalet tillåtna tecken utgör den stora skillnaden mellan TSA och SA. Att analysera sentiment på en text i ett twitterinlägg skiljer sig markant från att göra det på vanliga texter som återfinns i produktrecensioner och nyhetsartiklar. Det gör att TSA ställs inför en rad andra utmaningar än vad SA ställs inför.

I \cite{TSAsurvey} tar författarna upp de viktigaste utmaningar med TSA. För att bra resultat ska uppnås med TSA måste dessa utmaningar hanteras. Det som ligger till grund för utmaningarna med TSA är huvudsakligen restriktionen av antalet tillåtna tecken, att det är en informell typ av medium samt att innehållet på Twitter är dynamiskt och ständigt utvecklas.

Det låga antalet tillåtna tecken och att det är en informell typ av medium, gör att språket som används på Twitter skiljer sig från språket som används i vanlig text. Twitterinlägg innehåller ofta felaktigt språkbruk. Det är vanligt förekommande att Twitterinlägg innehåller förkortningar, slang,  nybildade ord och att ord betonas genom att de förlängs eller att de skrivs med versaler. 

På grund av att användandet av felaktigt språkbruk är så pass vanligt på Twitter, innehåller twitterinlägg en hel del brus. Felstavade termer gör att antalet gånger en specifik term förekommer i en mängd av text blir mindre. Det resulterar i datagleshet (data sparsity) och har en negativ påverkan på resultatet vid SA. För att minska dataglesheten omvandlas vanligtvis felstavade termer till den korrekta stavningen eller en mer korrekt stavning.

En annan utmaning med TSA är att hantera negationer, vilket även gäller SA. Om negationer förekommer i ett twitterinlägg kan det vända på inläggets sentiment. Därför är det viktigt att kunna tolka och identifiera negationer för att sentimentanalysen ska bli korrekt.

I många fall av SA analyseras texter som är skrivna på ett specifikt språk, exempelvis när nyhetsartiklar utgivna av en viss tidning analyseras. Vid TSA är det inte lika enkelt eftersom twitterinlägg kan vara skrivna på flera olika språk och det är inte ovanligt att språk blandas i inlägg. Den här studien kommer enbart analysera twitterinlägg skrivna på engelska och inhämtade inlägg skrivna på annat språk kommer filtreras bort. 

Vid TSA filtreras vanligtvis stoppord bort för att öka prestandan. Stoppord är ord som är vanligt förekommande i texter men som saknar någon större betydelse för texten ifråga. I engelskan är “the”, “is” och “who” exempel på stoppord.

Twitterinlägg behöver inte enbart innehålla text utan de kan även innehålla bilder och videor. Bilder och videor kan ge värdefull information om vad för sentiment som uttrycks i ett twitterinlägg. Det kan exempelvis ge information om vem som uttrycker en åsikt eller om vem en åsikt riktas mot. Den här studien kommer inte att ta hänsyn till mediaobjekt utan kommer enbart att analysera text. Främst på grund av att det i dagsläget är ett outforskat område.

\subsection{Problem} \label{TSAprob}
I \cite{TSAsurvey} listar författarna de problem med TSA som de anser bör utforskas ytterligare. Ett av de viktigaste problemen med TSA anser de vara bristen på datamängder som kan användas som riktmärken vid utvärdering av olika klassificeringsmodeller. Forskning som bedrivs i ämnet använder sig av olika datamängder. Dessutom är det vanligt att forskare själva samlar in och skapar egna datamängder som inte publiceras. Olika datamängder kan generera olika resultat. Därför är det svårt att jämföra olika klassificeringstekniker när det används flertalet olika datamängder. I experimentet, som presenteras i den här studien, har problemet adresserats genom att utvärderingen görs mot två kända och publika datamängder. Delvis för att kunna jämföra hur de olika klassificeringsmodellerna presterar mot olika typer av datamängder, men även för att kunna jämföra resultatet mot andra liknande utvärderingar.
\begin{table}
\centering
\caption{Förvirringsmatris}
\label{tab:fm}
	\begin{tabular}{ccc}
	\toprule
	 & \textbf{Förustspådd positiv} & \textbf{Förutspådd negativ} \\
	\midrule
	\textbf{Positiv} & Sann positiv & Falsk negativ \\
	\textbf{Negativ} & Falsk positv & Sann negativ \\
	\bottomrule
\end{tabular}
\end{table}

\section{Utvärdering} \label{TSAev}
I tabell \ref{tab:fm} ser vi en så kallad förvirringsmatris (FM) som utvärderar en klassificeringsmodell från datamängden där “positivt” eller “negativt” är förbestämt. Matrisen visar antalet sann positiv (SP), sann negativ (SN), falsk positiv (FP) och falsk negativ(FN) \cite{wiki:003}. Med dessa värden kan vi jämföra och analysera modellerna m.h.a följande utvärderingsmetoder: noggrannhet (n) \cite{wiki:011}, precision (p),  återkallelse (å) \cite{wiki:002} och F-Score \cite{wiki:001}.

\begin{labeling}{metrics}
\item [Noggrannhet] Är modellens förmåga att kunna märka ett twitterinlägg korrekt som antingen positivt eller negativt. Detta görs genom att ta summan av sannmärkta tweets delat på summan av alla märkningar.  
\item [Precision]  Är förmågan att modellen inte märker ett tweet som positivt när det är negativt. Detta görs genom att ta antalet sann positiva delat på totalt antal positivt märkta tweets. 
\item [Återkallelse] Är förmågan att modellen märker positiva tweets korrekt. Detta görs genom att ta antalet sann positiva delat på summan av antalet sann positiva och falsk negativa.
\item [F-Score] Även kallat det harmoniska medelvärdet mellan precision och återkallelse används då inte alltid precision och återkallelse räcker till för att göra en helhetsbedömning. 
\end{labeling}

I figur \ref{fig:utv} illustreras hur utvärderingmetoderna hänger ihop.

\begin{figure}[h]
\includegraphics[width=10cm]{utvardering}
\centering
\caption{Utvärderingsmetoder för TSA.}
\label{fig:utv}
\end{figure}


\section{Sammanfattning} \label{BACKsum}
I detta kapitel har bakgrunden till projektet diskuterats och där nyttan av SA och TSA har tagits upp. Intressant för uppdragsgivaren är hur de kan integrera SA och TSA i sina produkter t.ex. chatbotar och trendanalys. 

Detta kapitel ger även en överblick av vad maskininlärning är och hur maskininlärningens viktigaste komponenter hänger ihop samt hur maskininlärning kan appliceras på SA och TSA. Dessutom beskrivs de problem och utmaningar som existerar inom TSA. 

\chapter{Experiment}
I kapitlet kommer experimentet för studien att presenteras, hur det har utförts och hur de olika delarna har implementeras. Delarna utgörs av bearbetning av datamängderna, vilka särdragsurval som kommer utföras och en fördjupning i hur maskininlärningsalgoritmerna fungerar. Implementationen kommer ske i tre steg där först en lexikonbaserad modell kommer tas fram, för att ge ett basfall för respektive datamängd, för att sedan implementera algoritmerna med standardparametrar och slutligen testa och justera algoritmernas parametrar. Detta för att eventuellt uppnå en högre precision för respektive klassificeringsmodell. 
De slutgiltliga klassificeringsmodellerna kommer att diskuteras och jämföras i avsnitt \ref{res}.
\section{Bearbetning av datamängd} \label{exp:pre}
En viktig del inom SA är bearbetningen av den data som ska analyseras. Bearbetning av data, i fallet SA, handlar om att tvätta och förbereda texter som ska klassificeras \cite{effrosynidis2017comparison}. 

Kvaliteten på data som ska analyseras är avgörande för vilka resultat som kan uppnås vid maskininlärningen \cite{effrosynidis2017comparison}. I \cite{HADDI201326} rapporteras att bearbetning av text innan maskininlärning kan ha en tydlig positiv påverkan på en klassificeringsmodells prestanda vid sentimentanalays. Därför behöver data som ska analyseras bearbetas innan maskininlärningen, vilket betyder att data normaliseras och reduceras på brus. Teorin med att bearbeta en datamängd innan maskininlärningen är att det delvis kan förbättra prestandan för klassificeringsmodellen men även att  klassificering kan utföras snabbare, vilket kan vara av betydelse för sentimentanalys som utförs i realtid \cite{7862202}. 

Som nämndes i avsnitt \ref{TSAchall}, innehåller twitterinlägg vanligtvis stora mängder brus på grund av det informella språket som används på Twitter, dvs data som inte är användbar för analysprocessen. Det finns exempelvis många ord som inte har någon påverkan på en texts sentiment och därför är det vanligtvis inte nödvändigt att ta med alla ord från den ursprungliga texten vid maskininlärning \cite{effrosynidis2017comparison, HADDI201326}. Ord som dessa kan tas bort, ersättas eller slås samman med andra. Det är det som kallas för att bearbeta data. Genom att göra det minskas dimensionen på problemet och textklassificeringen blir enklare att utföra , eftersom varje ord behandlas som en dimension \cite{HADDI201326}. 

Det existerar flertalet olika tekniker som kan användas vid bearbetningen av data, vissa mer vanliga än andra. I arbetet med studien har två artiklar återfunnits som undersöker effekten av olika bearbetningstekniker vid TSA, \cite{effrosynidis2017comparison} och \cite{7862202}. Båda artiklarna utvärderar bearbetningsteknikerna utefter hur de påverkar prestandan vid sentimentklassificering.

\cite{effrosynidis2017comparison} utvärderar 15 olika bearbetningstekniker. Teknikerna utvärderas var för sig och testas mot två olika datamängder, där de för varje datamängd testas med tre olika klassificeringsmodeller.  Några bearbetningstekniker ger bättre noggrannhet för båda datamängderna, andra sämre och resultaten varierar för några. Resultaten varierar inte enbart mellan datamängderna utan de varierar även mellan klassificeringsmodellerna. De tekniker som rekommenderas av författarna och resulterar i hög noggrannhet för alla klassificeringsmodeller och de båda datamängderna är: borttagning av nummer, omvandling av ord till deras ursprungliga form samt ersättning av upprepade skiljetecken. Hantering av negationer, lemmatisering samt ersättning av URL:er och “mentions” av användare påvisar också bra resultat för båda datamängderna men dock inte för alla klassificeringsmodeller. Borttagning av skiljetecken var den bearbetningsteknik som gav sämst resultat. Det som saknas i \cite{effrosynidis2017comparison} är hur de olika förbehandlingsteknikerna presterar i kombination med varandra, vilket enligt författarna själva kan ge andra resultat.

Detta är dock något som görs i \cite{7862202}. Istället för att utvärdera varje teknik isolerat från varandra som i \cite{effrosynidis2017comparison}, utvärderas de istället utifrån hur de presterar i kombination med andra. Dock har de enbart har valt att fokusera på sex olika bearbetningstekniker: expandering av sammandragsförkortningar, expandering av förkortningar, avlägsning av nummer, avlägsning av stoppord, ersättning av förlängda ord och ersättning (borttagning) av URL:er. Bearbetningsteknikerna har utvärderats utefter hur de presterar på fem olika datamängder på fyra klassificeringsmodeller. Vid bedömningen av prestandan vid sentimentklassificeringen har ett basfall använts. Basfallet har använt samtliga sex bearbetningstekniker för bearbetningen av datan vid testningen. När en specifik teknik har utvärderats, har tekniken i fråga exkluderats från mängden av bearbetningstekniker. Därefter har testerna repeteras, med fem bearbetningstekniker istället för sex. Sedan har förändringen av resultatet gentemot basfallet använts för att bedöma hur tekniken påverkar prestandan vid sentimentklassificeringen. Resultaten visar att ersättning av negationer och expandering av förkortningar kan ha positiv påverkan på noggrannheten vid klassificeringen. Avlägsning av URL:er, nummer och stoppord påverkar resultaten för klassificeringen minimalt, men är effektiva för att minska brus. 

Utifrån resultaten som har presenterats i \cite{effrosynidis2017comparison} och \cite{7862202} har bearbetningsteknikerna för experimentet i den här studien valts. 
Det svåra med att välja bearbetningstekniker, utifrån litteraturen, är att det kan existera flera olika varianter av en viss teknik och att olika namn kan användas för att beskriva en viss teknik. I \cite{effrosynidis2017comparison} hanterar de exempelvis URL:er genom att ersätta varje URL med etiketten “URL”, medan de avlägsnas helt i \cite{7862202}. Eftersom bearbetningsteknikerna uteslutande kommer att användas i kombination med varandra vid det här experimentet har störst vikt lagts på de tekniker som presenteras i \cite{7862202}.

\begin{figure}[H]
\includegraphics[width=12cm]{dataset}
\centering
\caption{Bearbetningstekniker som används för att bearbeta data vid experimentet.}
\label{fig:dataset}
\end{figure}

Nedan presenteras och beskrivs de bearbetningstekniker som har valts att användas för experimentet. De valda teknikerna visualiseras i figur \ref{fig:dataset}. För några av bearbetningsteknikerna har ordningen betydelse. Exempelvis kommer inte expanderingen av sammandragsförkortningar kunna genomföras ifall avlägsnandet av accenter sker innan. Totalt har 12 bearbetningstekniker använts. Majoriteten av dessa handlar om att avlägsna text från twitterinläggen. Det som avlägsnas vid bearbetningen av twitterinläggen är: HTML-kod, accenter, URL:er, “mentions”, “hashtags”, skiljetecken, repeterande mellanslag och stoppord. Stoppord, som beskrevs i \ref{TSAchall}, tas bort genom att twitterinläggen söks igenom på stoppord från en fördefinierad lista. Även fast \cite{effrosynidis2017comparison} rapporterar sämre prestanda vid avlägsning av skiljetecken har det valts att användas som en bearbetningsteknik för det här experimentet. Det valet gjordes eftersom att \cite{effrosynidis2017comparison} samtidigt rapporterar att det bidrar till att reducera storleken på klassificeringsproblem. 

De övriga teknikerna som används omvandlar text under bearbetningen av ett twitterinlägg. Ett av de första stegen i den bearbetningsprocess, som har använts för detta experiment, är att omvandla versaler i ett twitterinlägg till gemener. Det gör att ord som är skrivna på flera olika sätt slås samman till ett \cite{effrosynidis2017comparison}. Vokabuläret blir då mindre, vilket gör att storleken på problemet minskas.

En annan teknik som används är att expandera sammandragsförkortningar.  I \ref{TSAchall} diskuterades vikten av att kunna tolka och identifiera negationer för att SA ska bli korrekt. Eftersom sammandragsförkortningar är vanligt förekommande i engelskan fokuserar tekniken på att expandera sammandragsförkortningar med motsägelser. Exempelvis är termen “don’t” exempel på en sammandragsförkortning för motsägelsen “do not”. För experimentet har sammandragsförkortningarna “n’t”, “can’t” och “won’t” omvandlas till “not”, “can not” och “will not”, utefter hur metoden beskrevs i \cite{7862202}.

Slutligen har också ordstamsigenkänning använts vid bearbetningen av ett twitterinlägg. Ordstamsigenkänning går ut på att ta bort ändelser från ord för att omvandla dem till deras ursprungliga form \cite{effrosynidis2017comparison}. Det leder också till att ord slås samman och att storleken på problemet minskar. Tabell \ref{tab:stemming} visar ett exempel på vad som sker då ordstamsigenkänning används på olika böjningar av det engelska ordet "arrive".

\begin{table}[H]
\centering
\caption{Exempel på vad som sker när ordstamsigenkänning används på olika böjningar av det engelska ordet "arrive".}
\label{tab:stemming}
    \begin{tabular}{cc}
    \multicolumn{2}{c}{\textbf{Ordstamsigenkänning}} \\
 	\toprule
    \textbf{Före} & \textbf{Efter} \\
    \midrule
    Arriving & Arriv \\
    Arrive & Arriv \\
    Arrives & Arriv \\
    \bottomrule
\end{tabular}
\end{table}

Tabell \ref{tab:preproc} visar ett exempel på vad som sker när ett twitterinlägg bearbetas med bearbetningsteknikerna som är valda för experimentet. 

\begin{table}[H]
\centering
\caption{Exempel på vad som sker med ett twitterinlägg efter det har bearbetas med alla valda bearbetningstekniker.}
\label{tab:preproc}
    \begin{tabularx}{\textwidth}{cX}
    \multicolumn{2}{c}{\textbf{Ordstamsigenkänning}} \\
    \midrule
    \textbf{Före}&  {@SportsCenter Hands down the Irish amateur, Paul Dunne, thrilled the world. More to come tomorrow!!! \#NICE https://t.co/kTYNkltfl6} \\
\textbf{Efter}& hand irish amateur paul dunn thrill world come tomorrow nice \\
    \bottomrule
\end{tabularx}
\end{table}





\section{Särdragsurval} \label{exp:feat}
Inom maskininlärning definieras ett särdrag som en individuell mätbar egenskap eller kännetecken på ett fenomen som har observerats, begreppet särdrag kommer från variabler som används inom statistik. Att välja korrekta, informativa och oberoende särdrag är ett kritiskt moment för att maskininlärningsalgoritmen ska kunna uppnå sin fulla potential och undvika fel klassificeringar \cite{wiki:014}. 
I \cite{TSAsurvey} presenteras det fyra olika särdragsklasser inom TSA: semantiska, syntaktiska, stilistiska och twitter-specifika särdrag.

\begin{figure}[H]
\includegraphics[width=9cm]{grams}
\centering
\caption{Illustrerar n-grams på en mening.}
\label{fig:grams}
\end{figure}

Semantiska särdrag används mestadels för att ta ut  åsiktsord, sentimentord och negationer. Åsiktsord är ord eller meningar som kan innehålla någon typ av åsikt medan sentimentord är ord som innehåller något positivt eller negativt. Negationer är ett viktigt koncept eftersom en mening som innehåller någon typ av negation kan skifta om twitterinlägget är positivt eller negativt. Studien kommer använda sentimentord i lexikonimplementationen som diskuteras i avsnitt \ref{impl:lex} och negationer som även diskuterats i avsnitt \ref{exp:pre} kommer implementeras i avsnitt \ref{impl:pre}.

Syntaktiska särdrag används för att utforska påverkan av olika termer i SA och TSA, syntaktiska särdrag bryts ner till unigram, bigram, trigrams, n-gram, termfrekvens och “Part of Speech” (POS). Där n-grams är ett samlingsord för uni-, bi- och trigram, i figur \ref{fig:grams} illustreras hur n-gram modellen fungerar på en enkel mening och hur meningens ord grupperas på olika sätta till ett ord eller fras. **ta upp något om varför det används?**

Termfrekvens kan används i kombination med n-gram. Längre twitterinlägg kan ha ett högre antal förekomster av ett ord än ett kortare twitterinlägg, vilket kan leda till att ord kan få större betydelse för klassificeringen. Genom användandet av termfrekvens delas antalet förekomster av ett ord i ett twitterinlägg med alla ord som finns i twitterinlägget undviks sådana problem \cite{scikit:001}.

POS utförs genom att man räknar hur många substantiv, verb och adjektiv som existerar i ett twitterinlägg. POS kan t.ex användas för att ta redan på åsikter i ett twitterinlägg där antalet adjektiv kan relateras till vilken åsikt ett twitterinlägget har.

Studien kommer implementera n-grams och termfrekvens för varje klassificeringsalgoritm i \ref{impl}. POS kommer inte implementeras i studien då \cite{go2009twitter} och \cite{feature:001} rapporterar försämrad precision. Däremot rapporterar \cite{feature:002} små förbättringar vid användning av POS.

Stilistiska särdrag är särdrag som kommer från det informella skrivsättet som används på Twitter där t.ex emojis, förkortningar, slang och skiljetecken används. Enligt \cite{feature:002} kan emojis ha en stor betydelse för TSA. Men eftersom STS datamängden har avlägsnat emojis, då “distant supervision” \cite{sts:001} har använts, kommer inte studiens modeller ta hänsyn till emojis. Därför har även emojis från SemEval-datamängden filtreras bort i \ref{exp:pre}. Studien kommer inte hantera slang eftersom inget större slanglexikon var öppet för användning. 
Förkortningar och skiljetecken kommer hanteras i denna studie och har diskuterats i avsnitt \ref{exp:pre} och implementeras i avsnitt \ref{impl:pre}.

Twitter-specifika särdrag är särdrag som är specifika för Twitters domän som t.ex “hashtags” och “mentions” vilket diskuteras i \ref{TSA} och \ref{exp:pre}.




\section{Algoritmer}
** Skall det skrivas något kort intro här?***
\subsection{Naive Bayes}
I \ref{MLnb} beskrivs det att Naive Bayes algoritmen är baserad på Bayes theorem  \cite{wiki:009} vilket för TSA betyder att räkna ut sannolikheten om ett twitterinlägg $B$ är positivt eller negativt $A$. Där $P(A | B)$ är en villkorlig sannolikhet för att $A$ inträffar givet att $B$ är sant, $P(B | A)$ är också en villkorlig sannolikhet för att $B$ inträffar givet att $A$ är sant. $P(A)$ och $P(B)$ är sannolikheten att observera $P(A)$ och $P(B)$ oberoende av varandra,
\begin{equation}\label{eq:bt}
P(A|B) = \frac{P(B|A) * P(A)}{P(B)}.
\end{equation}

För att ekvation \ref{eq:bt} skall vara naiv antas att varje ord $b_w$ i $B$ är oberoende av varandra vilket betyder att vi inte längre klassificerar $B$ utan $b_w$, $P(B|A) = P(b_{w1}|A) * P(b_{w2}|A) * … * P(b_{wn}|A)$, där $n$ är antalet ord i $B$.

För att beräkna sannolikheten att $b_w$ är $A$ används Dirichlet prior \cite{wiki:012, nb:007}, där $N_{b_w}$ är hur många gånger $b_w$ förekommer i delmängden av data för $A$, $N_A$ är summan av alla ord i delmängden för $A$, $\alpha$ och $\alpha_n$ används för att utföra additiv utjämning \cite{wiki:013} där $\alpha = 1$ och $\alpha_n$ är summan antal möjliga ord som existerar i hela datamängden, 

\begin{equation}\label{eq:slut}
P(w_b|A)= \frac{N_{b_w} + \alpha}{N_A + \alpha_n}.
\end{equation}

\begin{table}
\centering
\caption{Exempel datamängd om ett twitterinlägg är positiv eller negativ}
\label{tab:dataset}
    \begin{tabular}{ccc}
    \toprule
    \textbf{Twitterinlägg} & \textbf{Märkning} \\
    \midrule
    ser fram emot en dag i solen & Positiv \\
    jävla skit väder & Negativ \\
    vilken jävla kung du är linkan & Positv \\
    fyfan vilken dålig match & Negativ \\
    \bottomrule
\end{tabular}
\end{table}

I tabell \ref{tab:dataset} illustreras en datamängd med fyra twitterinlägg och dess märkning, denna datamängden kan användas för att beräkna om twitterinlägget “solen skiner alltid i karlstad” är positiv eller negativ. Genom att räkna ut sannolikheten $P(Positiv|\textrm{solen skiner alltid i karlstad})$ och $P(Negativ|\textrm{solen skiner alltid i karlstad})$ kan märkning bestämmas, detta görs genom att jämföra vilken sannolikhet som blir störst. Och eftersom vi ska jämföra uträkningarna mellan varandra kan divisionen med $P(B)$ strykas ur bägge uträkningarna och vi för följande ekvationer,
\begin{multline*}
P(Positiv|\textrm{solen skiner alltid i karlstad}) = P(solen|Positiv) * P(skiner|Positiv) * \\P(alltid|Positiv) * P(i|Positiv) * P(karlstad|Positiv)*P(Positiv)
\end{multline*}
\begin{multline*}
P(Negativ|\textrm{solen skiner alltid i karlstad}) = P(solen|Negativ) * P(skiner|Negativ) \\ * P(alltid|Negativ) * P(i|Negativ) *  P(karlstad|Negativ) * P(Negativ)
\end{multline*}

För att räkna ut exempelvis $P(solen|Positiv)$ används ekvation \ref{eq:slut} där $N_{b_w} = 1$, $N_A= 13$, $\alpha_n = 18$ och $\alpha = 1$ vilket ger oss $P(solen|Positiv) =  \frac{1 + 1}{13 + 18} = 0.0645$. I tabell \ref{tab:ekv} illustreras alla ekvationer för att beräkna om “solen skiner alltid i karlstad” är positiv eller negativ. Ovanstående utförs på varje ord för både positiv och negativ vilket illustreras i tabell \ref{tab:ekv}.  Med hjälp av tabell \ref{tab:ekv} beräknas 
\begin{multline*}
P(solen|Positiv) * P(skiner|Positiv) * P(alltid|Positiv) * P(i|Positiv) *  \\P(karlstad|Positiv) * P(Positiv) = 1.363 * 10^{-7}
\end{multline*}
och
\begin{multline*}
P(solen|Negativ) * P(skiner|Negativ) * P(alltid|Negativ) * P(i|Negativ) *  \\P(karlstad|Negativ) * P(Negativ) = 1.024 * 10^{-7}.
\end{multline*}

Jämförs dessa resultat kommer twitterinlägget klassificeras som positiv. 


\begin{table}
\centering
\caption{Beräkningar för om ett ord är positivt eller negativt.}
\label{tab:ekv}
    \begin{tabular}{ccc}
    \toprule
    \textbf{Ord} & \textbf{P(ord|Positiv)} & \textbf{P(ord|Negativ)} \\
    \midrule
    solen & $\frac{1 + 1}{13 + 18} $ & $\frac{0 + 1}{7 + 18} $\\
    skiner & $\frac{0 + 1}{13 + 18} $ & $\frac{0 + 1}{7 + 18}$ \\
    alltid & $\frac{0 + 1}{13 + 18}$ & $\frac{0 + 1}{7 + 18}$ \\
    i & $\frac{1 + 1}{13 + 18} $& $\frac{0 + 1}{7 + 18}$ \\
karlstad & $\frac{0 + 1}{13 + 18}$ & $\frac{0 + 1}{7 + 18}$ \\
    \bottomrule
\end{tabular}
\end{table}


\subsection{Support Vector Machine}
I avsnitt \ref{MLsvm} beskrevs SVM kortfattat, i följande avsnitt kommer SVM att beskrivas mer ingående. SVM-algoritmen skapar en modell utifrån en given mängd märkt träningsdata \cite{svm:002}. Modellen som skapas har sedan förmågan att kategorisera ny indata i en av de två kategorierna. Den skapade SVM-modellen representerar träningsdata som punkter i ett koordinatsystem. I koordinatsystemet kartläggs data så att de två kategorierna är tydligt separerade med ett så stort mellanrum som möjligt. När modellen kategoriserar ny indata kartläggs den datan till samma koordinatsystem, för att sedan kategoriseras utefter vilken sida av mellanrummet den hamnar på.  

\begin{figure}[H]
\includegraphics[width=9cm]{linearsvm_hpwithmargins}
\centering
\caption{Exempel på en linjär klassificerare där de två kateogrierna är linjärt separabla.}
\label{fig:svmmarg}
\end{figure}  

För att separera kategorierna konstruerar SVM ett hyperplan \cite{svm:003}. I figur \ref{fig:svmmarg} representeras hyperplanet av linjen mellan kategorierna. Datapunkterna som ligger närmast hyperplanet för respektive kategori kallas för stödvektorer och de är utefter de punkterna som hyperplanet positioneras. Det kan finnas flera möjliga hyperplan som kan kategorisera datan. Idén bakom SVM är att hitta hyperplanet som bäst delar upp datamängden i två kategorier. Ju större marginal mellan kategorierna desto mindre känslig blir modellen för generaliseringsfel \cite{svm:002}. Därför anses hyperplanet som har störst marginal till de närmaste stödvektorerna från respektive kategori ge en bra separation av data.

\begin{figure}[H]
\includegraphics[width=9cm]{nonlinearsvm}
\centering
\caption{Exempel på en linjär klassificerare där de två kategorierna inte är linjärt separabla.}
\label{fig:svmnonl}
\end{figure} 

Exemplet i figur \ref{fig:svmmarg} representerar en linjär klassificerare, då de två kategorierna  är linjärt separabla.  Dock finns det klassificeringsproblem som inte går att separera linjärt, så kallade icke-linjära klassificeringsproblem. Figur \ref{fig:svmnonl} visar ett exempel på ett sådant problem. SVM kan även hantera sådana klassificeringsproblem. I fall som dessa ritar SVM om datapunkterna till en högre dimension för att en separation ska bli möjlig \cite{svm:003}, vilket illustreras i figur \ref{fig:svm3d}. Processen upprepas tills dess att ett hyperplan kan separera datan.  Metoden SVM använder för att utföra detta effektivt kallas “kernel trick” \cite{svm:004}. 

\begin{figure}[H]
\includegraphics[width=9cm]{svm_3d}
\centering
\caption{Exempel på icke-linjär klassificerare, där hyperplanet har dragits i en högre dimension.}
\label{fig:svm3d}
\end{figure} 

Om ett problem kräver en linjär eller en icke-linjär klassificerare beror på hur den data som ska klassificeras ser ut. Beteendet för SVM-algoritmen går att anpassa utefter den data som ska klassificeras genom att välja olika “kernel”-funktioner \cite{svm:006}. För textklassificering är det rekommenderat att använda en linjär “kernel”, vilket ger en linjär klassificerare. Anledningen till det är dels att de flesta textklassificeringsproblem är linjärt separerbara. Men det är även bra att använda en linjär “kernel” när antalet särdrag för klassificeringsproblemet är högt, vilket är fallet vid textklassificering. När antalet särdrag är högt är det ingen märkbar skillnad i prestanda mellan en linjär kontra icke-linjär “kernel”. Dessutom går en SVM-modell med en linjär “kernel” snabbare att träna än andra och det är färre parametrar som behöver justeras vid optimering av en modell. 
På grund av ovanstående anledningar har en linjär klassificerare valts att användas vid den här studien. 

\subsection{Convolutional Neural Network}




\section{Implementation}\label{impl}
\section{Databearbetning}\label{impl:pre}
\subsection{Lexikon}\label{impl:lex}
\subsection{Naive Bayes}\label{impl:nb}
\subsection{Support Vector Machine}\label{impl:svm}
\subsection{Prediction program.}
\subsection{* ev GUI implementation om tid finns *}
\section{Sammanfattning}

\chapter{Resultat} \label{res}
\section{Intro}
\section{Resultatet mellan modellerna}
\subsection{Dataset 1 -> jämför resultat mellan modellerna}
\subsection{Dataset 2 -> jämför resultat mellan modellerna}
\subsection{Dataset 3 -> jämför resultat mellan modellerna}
\newpage
\section{Implementations mässigt vilken modell är lättast?}
\section{implementations jämförelse (resultat VS förväntat)}
\section{Summering}

\chapter{Slutsats}
\section{Sammanfattning}
\section{Problem}
\section{Begränsningar}
\newpage
\section{Vidare utveckling}
\section{Slutord}



\bibliographystyle{unsrtnat} 
\bibliography{../refs/thesisref}


\restoregeometry%

\end{document}
\endinput
%%
%% End of file `kaumasterstemplate.tex'.
