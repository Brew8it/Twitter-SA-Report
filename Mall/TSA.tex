%%
%% This is file `kaumasterstemplate.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% kauthesis.dtx  (with options: `masterstemplate')
%% 
%% This is a generated file.
%% 
%% Copyright (c) 2011-2014 Stefan Berthold <stefan.berthold@kau.se>
%% 
%% This file is part of the kauthesis bundle.
%% 
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%% 
%% This work has the LPPL maintenance status `author-maintained'.
%% 
%% The Current Maintainer and author of this work is Stefan Berthold.
%% 
%% This work consists of all files listed in manifest.txt.
%% 
%% kauthesis.dtx
%% Copyright (c) 2011-2015 Stefan Berthold <stefan.berthold@kau.se>

\documentclass{kaumasters} % available class options: garamond
\usepackage[swedish]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{titletoc}
\usepackage{geometry}
\usepackage{booktabs}

\usepackage{float}




%% break long URLs in references.
\usepackage{url}
\def\UrlBreaks{\do\/\do-}
% list
\usepackage{scrextend}
\addtokomafont{labelinglabel}{\sffamily}

\usepackage{fancyhdr}

\usepackage{graphicx}
\graphicspath{{../figures/background/}}
\usepackage[numbers]{natbib}

% clickable

\renewcommand{\baselinestretch}{1.5} 


\makeatletter
\renewcommand\scriptsize{\@setfontsize\scriptsize{7}{8}}
\renewcommand\tiny{\@setfontsize\tiny{5}{6}}
\renewcommand\small{\@setfontsize\small{5}{6}}
\renewcommand\normalsize{\@setfontsize\normalsize{12}{12}}
\renewcommand\large{\@setfontsize\large{10.95}{15}}
\renewcommand\Large{\@setfontsize\Large{12}{16}}
\renewcommand\LARGE{\@setfontsize\LARGE{14.4}{18}}
\renewcommand\huge{\@setfontsize\huge{20.74}{30}}
\renewcommand\Huge{\@setfontsize\Huge{24}{36}}
\makeatother
\usepackage{sectsty}

\chapterfont{\Huge}
\sectionfont{\huge}
\subsectionfont{\LARGE}
\subsubsectionfont{\Large}
\paragraphfont{\Large}


%\pagestyle{fancy}
%\fancyhf{}
%\lhead[\texttit{}]{}
%\rhead[]{}
%\setlength{\headheight}{15pt}

\title{Twitter Sentiment Analysis}
\author{Johan Selberg, Johannes Bandgren}
\supervisor{Kerstin Andersson}
\examiner{Exam}
\institute{Department of Computer Science}
\place{Karlstad Universitet}
\begin{document}

\maketitle




\frontmatter
\begin{abstract}
  Abstract.
  \keywords keywords
\end{abstract}
\approvalpage%
\begin{acknowledgements}
  Thanks.
\end{acknowledgements}

\tableofcontents{}
\listoffigures
\listoftables
\mainmatter
% för att fucka med marginaler
%\newgeometry{top=20mm, bottom=20mm, right=30mm, left=30mm}
\pagestyle{fancy}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE,LO]{\rightmark}
\fancyfoot{}
\chapter{Introduktion}

\newpage


\chapter{Bakgrund}
\section{Introduktion} \label{bac:intro}
Syftet med studien är att utvärdera (x) stycken klassificeringsmodeller inom maskininlärning och hur bearbetningen samt märkningen av en datamängd påverkar en klassificeringsmodells prestanda. Maskininlärningsalgoritmerna som kommer att användas för att få fram klassiciferingsmodellerna är Naive Bayes (NB), Support Vector Machine (SVM) och ZZZZZ. Figur \ref{fig:overfig} visar en förenklad bild av hur processen för att utvärdera klassificeringsmodellerna kommer att se ut. Datamängden består av en mängd indata som är märkt med förväntad utdata, som går igenom en bearbetningsprocess där t.ex. data som inte tillför något värde tas bort och där mängden av data delas upp i tränings- och valideringsdata.  Bearbetningsprocessen diskuteras mer ingående i \ref{exp:pre}. På den bearbetade datan utförs ett särdragsurval, där dataspecifika särdrag plockas ut…MER .. som diskuteras vidare i \ref{exp:feat}. Träningsmängden används av maskininlärningsalgoritmen för att skapa klassiciferingsmodellen. När klassificeringsmodellen är framtagen används valideringmängden för att utvärdera prestandan av modellen.

\begin{figure}[h]
\includegraphics[width=12cm]{oversiktsfigur}
\centering
\caption{Utvärderingsprocessen av maskininlärningsmodeller}
\label{fig:overfig}
\end{figure}

Studien kommer att använda maskininlärning för att utföra sentimentanalys (SA) d.v.s utläsa huruvida en text uttrycker någonting positivt eller negativt. Uppdragsgivaren, CGI, betraktar sentimentanalys  som en viktig pusselbit för framtida lösningar man vill erbjuda sina kunder. Lösningar skulle kunna vara chatbotar där sentimentanalys används så att chatboten ändrar sitt språk utefter svaren från slutanvändare. Eller att det kan användas för trendanalys där ett företag vill veta vad allmänheten tycker före och efter att man har släppt en ny produkt eller efter att kvartalsrapporten har släppts.

I avsnitt \ref{SA} förklaras vad SA är och olika klassificeringstekniker inom SA berskrivs kortfattat. I avsnitt \ref{ML} ges en kort introduktion till maskininlärning och framstegen som gjorts under den senaste tiden. Dessutom beskrivs NB och SVM samt hur inlärningsprocessen ser ut. I avsnitt \ref{DS} ges en överblick över hur en datamängd ser ut och vilka märkningsmetoder som används för twittersentimentanalys (TSA). Avsnittet beskriver även de valda datamängderna. I avsnitt \ref{TSA} ges en introduktion till TSA och vilka utmaning samt problem TSA har. Slutligen i avsnitt \ref{TSAev} förklaras vilka hjälpmedel som kommer att användas för att utvärdera algoritmernas prestanda.


\section{Sentimentanalys} \label{SA}
SA används för att studera människors åsikter, attityder och känslor mot olika entiteter. En entitet kan vara ett ämne, en händelse eller en individ. Målet med SA är att identifiera känslan som är uttryckt i en text för att därefter analysera den. Processen delas upp i tre steg: att hitta entiteter, identifiera känslan för de entiteterna och slutligen klassificera dessa entiteter. \cite{SAsurvey}.

Inom SA appliceras klassificeringen på 3 olika nivåer: dokument-, menings- och aspektnivå \cite{SAsurvey}. SA på dokumentnivå klassificerar om ett helt dokument uttrycker en positiv eller negativ åsikt, exempel på dokument kan vara produktrecensioner eller nyhetsartiklar. Medan på meningsnivå klassificeras varje mening i ett dokument. Slutligen nere på aspektnivå analyseras de möjliga aspekterna av en entitet. En mening kan behandla olika aspekter av en entitet. Både positiva och negativa åsikter kan delges om en entitets olika aspekter. Ett exempel på det är meningen “Ölen var väldigt god, men tyvärr alldeles för dyr”, som innehåller både en positiv och en negativ åsikt om en entitet som i det här fallet är ölen.
\subsection{Klassificeringstekniker} \label{SAkt}
De olika klassificeringsteknikerna som i nuläget används för SA delas upp i 3 olika kategorier: maskininlärningsmetoder, lexikonbaserade metoder samt hybrida metoder \cite{SAsurvey}. 

Maskininlärningsmetoder använder etablerade maskininlärningsalgoritmer tillsammans med språkliga särdrag för att konstruera klassificerare som kan avgöra om en text uttrycker någonting positivt eller negativt [ref=Sentiment analysis a survey]. Prestandan för maskininlärningsmetoder är beroende av mängden träningsdata, större mängder data ger vanligtvis bättre resultat \cite{TSAsurvey}. Maskininlärningsmetoder är dessutom domänberoende, vilket gör att de inte presterar bra när de används på andra domäner än det de har tränats på. 

Lexikonbaserade metoder använder sig av ordlistor för att analysera text \cite{SAsurvey}. Ordlistorna består av positiva och negativa termer som används för att beräkna vad en given text uttrycker för sentiment.
Fördelen med lexikonbaserade metoder är att de inte kräver någon  träningsdata \cite{TSAsurvey}. Men faktumet att de är beroende av statiska ordlistor betyder att de inte tar hänsyn till termer som inte finns i ordlistorna. Det betyder att ordlistor måste uppdateras kontinuerligt för innehåll som är dynamiskt och ständigt under utveckling, vilket är särskilt problematiskt för texter som förekommer på sociala medier. 

Hybrida metoder kombinerar lexikonbaserade metoder med maskininlärningsmetoder \cite{TSAsurvey}. Genom att kombinera metoderna med varandra kan de väga upp för varandras svagheter. Nackdelen med hybrida metoder är dock att de kräver en hög beräkningskomplexitet.

Experimentet som presenteras i studien fokuserar enbart på maskininlärningsmetoder.

\section{Maskininlärning} \label{ML}
Maskininlärning är ett delområde inom artificiell intelligens (AI), där målet är att göra det möjligt för datorer att lära sig på egen hand. Maskininlärningsalgoritmer gör det möjligt att identifiera olika mönster från observerad data, bygga upp en generell modell som kan förutsäga saker utan att ha blivit förprogrammerade med explicita regler för hur den ska lösa ett problem. Under de senaste åren har stora framsteg inom maskininlärning gjorts. Exempelvis utvecklade DeepMind \cite{DMatari00} 2015 en agent som mästrade 49 st Atari-spel \cite{wiki:004}, med en klassificeringsmodell med endast pixlar och spelpoäng som indata. Under 2016 utvecklade DeepMind sin AlphaGo \cite{DMgo} agent som besegrade en av världens bästa Go spelare, Lee Sedol \cite{wiki:005} med 4-1 i matcher. Detta var ett framsteg för AI eftersom Go är ett komplext spel med $2 * 10^{170}$ möjliga drag \cite{wiki:006}.

Maskininlärning används också för att lösa vardagliga problem. I dagens mobiltelefoner finns en så kallad intelligent personlig assistent, även kallade Siri \cite{siri} och Google Assist \cite{google},  där användarna får hjälp med t.ex. “vad är det för väder idag?”, “Skicka ett meddelande till mamma att jag blir sen till middagen idag” och “Påminn mig imorgon att jag måste köpa mjölk”. Facebook använder även maskininlärning för ansiktsigenkänning \cite{facebook:001} på bilder som laddas upp, och för att rekommendera nya vänner \cite{facebook:002}. 

%\section{Övervakad och oövervakad inlärning} \label{MLvised}
Figur \ref{fig:ml} illustrerar att maskininlärning delas upp i två typer av inlärningsprocesser dvs. i övervakad eller oövervakad inlärning och deras underliggande algoritmer.
\begin{figure}[h]
\includegraphics[width=12cm]{ml}
\centering
\caption{Inlärningsprocesser för maskininlärning.}
\label{fig:ml}
\end{figure}

Oövervakad inlärning används när datamängden bara består av indata och inget förväntat resultat. Målet med oövervakad inlärning är att algoritmen själv lär sig att modellera den komplexa underliggande strukturen så att den kan lära sig mer om datan och själv komma fram till ett resultat \cite{wiki:007}. Exempelvis kan en oövervakad klusteralgoritm användas för att hitta likheter i bilder och följaktligen gruppera dem.
Övervakad inlärning används när datamängden består av både indata och dess förväntade utdata. Den övervakade algoritmen använder datamängden för att lära sig hur utdata beror på indata genom att skapa en klassificeringsmodell som används för att förutse utdata från ny indata som illustreras i figur \ref{fig:kl}. 

Övervakad inlärning kan man tänka sig som att en lärare övervakar programmets inlärningsprocess. Under inlärningsprocessen försöker algoritmen iterativt förutse utdata från datamängden och blir rättad av läraren vid fel förutsägelse \cite{learning:001}.

\begin{figure}[h]
\includegraphics[width=12cm]{klassmodell}
\centering
\caption{Klassificeringsprocess av data.}
\label{fig:kl}
\end{figure}

Övervakad inlärning kan brytas ner till klassificerings- och regressionsproblem och eftersom TSA kan kallas ett typiskt klassificeringsproblem \cite{SAsurvey}, kommer studien att använda algoritmer lämpade för klassificeringsproblem. I figur \ref{fig:ml} kan vi se några av dessa klassificeringsalgoritmer och enligt \cite{TSAsurvey} är speciellt Naive Bayes (NB) och Support Vector Machine (SVM)  bäst lämpade för TSA.

\subsection{Naive Bayes} \label{MLnb}
NB är en klassificeringsalgoritm som är baserad på Bayes theorem \cite{wiki:009} med starka (“naive”) oberoende antaganden mellan särdragen d.v.s NB förutsätter att närvaron av ett visst särdrag i en klass inte relaterar till närvaron av ett annat särdrag. 
Exempelvis kan en frukt anses vara ett äpple om det är grönt, runt och är 10 cm i diameter. Även om särdragen grönt, runt och diameter kan bero på varandra så bidrar alla särdragen självständigt till sannolikheten att frukten är ett äpple, det är därför algoritmen kallas (“naive”) \cite{nb:001}.

\subsection{Support Vector Machine} \label{MLsvm}
SVM är en övervakad maskininlärningsalgoritm som kan användas till både klassificerings- och regressionsproblem, för det mesta används SVM för klassifikationsproblem. SVM är baserat på idén att hitta ett hyperplan \cite{svm:001} som bäst delar upp datamängden i två klasser \cite{svm:003}. Givet en träningsmängd där förväntad utdata är markerad till en av två kategorier bygger SVM-algoritmen upp en klassificeringsmodell som kan användas för att förutse vilken kategori ny indata ger \cite{svm:002}. 

\subsection{XXX}

\section{Datamängd} \label{DS}
En datamängd för övervakad inlärning består av en mängd in- och utdata som diskuteras i sektion \ref{ML}. Processen för hur rätt utdata (positiv/negativ) märks kan utföras på två olika sätt, antingen genom så kallad mänsklig märkning där människor markerar indata som positiv/negativ eller genom “distant supervision” där en dator märker indata som positiv/negativ utefter någon parameter. Den stora skillnaden mellan mänsklig märkning och “distant supervision” är att “distant supervision” kan generera en mycket större datamängd än mänsklig märkning men risken är större att märkningen blir felaktig \cite{TSAsurvey}. 
Som är beskrivit i sektion \ref{bac:intro} är ett delsytfte med denna studie att utvärdera hur de olika märkningsmodellerna påverkar maskininlärningsalgoritmernas precision. Det finns ett urval med publika twitterdatamängder där både mänsklig märkning och “distant supervison” används \cite{TSAsurvey}. Vi har valt att använda datamängderna Stanford Twitter Sentiment (STS) \cite{sts:001} och SemEval \cite{SemEval:001} eftersom de är de största publika datamängderna inom respektive märkningsmodell.

\subsection{SemEval} \label{DSse}
SemEval-datamängden består av 20633 tweets och är framtagen till en årlig TSA-tävling som har gått sedan 2013 \cite{SemEval:002}. 
För datamängden har mänsklig märkning tillämpats, där fem personer manuellt märker varje tweet via Amazon Mechanical Turk \cite{SemEval:003}.
I \cite{SemEval:004} beskrivs metoden för hur märkningen utförs, varje person markerar varje tweet antingen som mycket positivt, positivt, neutralt, negativt eller mycket negativt. Efter att alla tweets är märkta kartläggs alla tweets till kategorierna positivt, neutralt eller negativt utefter tre kriterier. Antingen att alla personer har märkt en tweet samma, en majoritet har märkt samma eller genom att ta ut ett medelvärde. Medelvärdet räknas ut genom att kartlägga de fem kategorierna till heltal mellan 2 och -2, medelvärdet räknas sedan ut och kartläggs till den närmsta kategorin. För SemEval-datamängden blev utfallet 2760 tweets där alla personer gjort samma märkning, 9944 tweets är där majoritet har märkt samma och för resterande 7928 tweets har medelvärdet räknats ut. 

\subsection{Stanford Twitter Sentiment} \label{DSsts}
STS-datamängden är framtagen mellan April 2009 och Juni 2009 av Alec Go, Richa Bhayani och Lei Huang. STS-datamängden är märkt med hjälp av “distant supervision” där märkningen bestäms av vilken typ av emoji \cite{wiki:010} ett twitterinlägg innehåller, exempelvis märks ett twitterinlägg positivt om det innehåller “:), :-),: ), :D, =)” och negativt om det innehåller “:(, :-(, : (“ \cite{sts:001}. 

\section{Twittersentimentanalys} \label{TSA}
TSA är den del av SA som specifikt handlar om att analysera inlägg som användare gör på Twitter. Twitter är en av de populäraste mikrobloggarna där användare kan skriva och kommunicera med varandra genom twitterinlägg. 2013 var Twitter en av de tio mest besökta sidorna på internet och 2016 uppmättes antalet aktiva användare per månad till 319 miljoner. Twitter är definierat som en mikroblogg på grund av det låga antalet tecken som är tillåtet för ett inlägg. I November 2017 fördubblades antalet tillåtna tecken från de tidigare 140 till 280 \cite{wiki:008}. 

Det finns en rad olika begrepp som kännetecknar Twitter och som är viktiga att känna till \cite{TSAsurvey}. En “tweet” är vad som tidigare nämnts ett twitterinlägg. Det är ett inlägg från en användare som är begränsat till 280 tecken, där användaren exempelvis kan delge sina åsikter i olika ämnen eller dela med sig av personliga upplevelser. En “tweet” behöver inte enbart innehålla ren text utan kan även innehålla länkar, bilder och videor. I fortsättningen av rapporten kommer en “tweet” att benämnas twitterinlägg.

När ett twitterinlägg innehåller “mentions” betyder det att andra användare nämns i inlägget. Det kan vara användbart för att exempelvis delge åsikter om andra användare eller för att öppet starta en diskussion med en nämnd användare. För att nämna en användare i ett twitterinlägg skrivs symbolen @ före användarnamnet. 

På Twitter har användare möjligheten att följa andra användare. Det betyder att användare kan följa andra användares aktivitet i deras egna twitterflöden och dela med sig av sin egen aktivitet till sina följares twitterflöden. En användare som följer en annan benämns på Twitter som en “follower”. Att följa andra är det primära tillvägagångssättet för att skapa kontakter med andra användare på Twitter. 

Användare har möjlighet att kategorisera twitterinlägg och det är vad “hashtags” används för. Genom att använda “hashtags” kan användare märka sina twitterinlägg med etiketter för att knyta inlägget till ett specifikt ämne. Användandet av hashtags gör det enkelt för användare att följa ett ämne. De behöver enbart söka på en specifik “hashtag” för att få fram alla twitterinlägg i ämnet. För att skapa en “hashtag” skrivs symbolen \# före namnet på etiketten.

Det är även möjligt att dela andra användares twitterinlägg till ens egna följare. Den funktionen kallas för “retweet” och ett sådant twitterinlägg startar vanligtvis med förkortningen RT följt av en “mention” av den ursprungliga författaren av twitterinlägget. Det kan exempelvis vara användbart för att sprida information till följare eller för att skapa en diskussion om innehållet i twitterinlägget med sina egna följare. 

När användare svarar på andras twitterinlägg benämns det som “replies” och det är till för att det ska gå att skapa konversationer, där det ska gå att urskilja vanliga twitterinlägg från svar på twitterinlägg. En användare svarar på ett twitterinlägg genom att göra en referens till den ursprungliga författaren av inlägget följt av svaret på inlägget.

Användare behöver inte göra alla sina inlägg offentliga för alla användare, de kan begränsa synligheten för deras twitterinlägg att enbart synas för deras egna följare. 

I figur \ref{fig:tweet} presenteras ett exempel på hur ett twitterinlägg kan se ut. Twitterinlägget är en “retweet som ursprungligen har skrivits av användaren johanselberg. Det innehåller en “hashtag” med etiketten exempel och en “mention” av användaren KAU. Twitterinlägget innehåller även en extern länk.

\begin{figure}[h]
\includegraphics[width=12cm]{exempeltweet}
\centering
\caption{Twitterinlägg innehållande ''hashtag'', ''mention'', ''retweet''.}
\label{fig:tweet}
\end{figure}

\subsection{Utmaningar} \label{TSAchall}
På grund av restriktionen av antalet tillåtna tecken i ett twitterinlägg innehåller majoriteten av twitterinlägg enbart en mening. Därför är det skillnad på klassificeringsnivåerna i TSA och SA. I TSA är det ingen skillnad på dokument- och meningsnivå. Därför används det enbart två klassificeringsnivåer inom TSA: meningsnivå (meddelandenivå) och aspektnivå. \cite{TSAsurvey}

Restriktionen av antalet tillåtna tecken utgör den stora skillnaden mellan TSA och SA. Att analysera sentiment på en text i ett twitterinlägg skiljer sig markant från att göra det på vanliga texter som återfinns i produktrecensioner och nyhetsartiklar. Det gör att TSA ställs inför en rad andra utmaningar än vad SA ställs inför.

I \cite{TSAsurvey} tar författarna upp de viktigaste utmaningar med TSA. För att bra resultat ska uppnås med TSA måste dessa utmaningar hanteras. Det som ligger till grund för utmaningarna med TSA är huvudsakligen restriktionen av antalet tillåtna tecken, att det är en informell typ av medium samt att innehållet på Twitter är dynamiskt och ständigt utvecklas.

Det låga antalet tillåtna tecken och att det är en informell typ av medium, gör att språket som används på Twitter skiljer sig från språket som används i vanlig text. Twitterinlägg innehåller ofta felaktigt språkbruk. Det är vanligt förekommande att Twitterinlägg innehåller förkortningar, slang,  nybildade ord och att ord betonas genom att de förlängs eller att de skrivs med versaler. 

På grund av att användandet av felaktigt språkbruk är så pass vanligt på Twitter, innehåller twitterinlägg en hel del brus. Felstavade termer gör att antalet gånger en specifik term förekommer i en mängd av text blir mindre. Det resulterar i datagleshet (data sparsity) och har en negativ påverkan på resultatet vid SA. För att minska dataglesheten omvandlas vanligtvis felstavade termer till den korrekta stavningen eller en mer korrekt stavning.

En annan utmaning med TSA är att hantera negationer, vilket även gäller SA. Om negationer förekommer i ett twitterinlägg kan det vända på inläggets sentiment. Därför är det viktigt att kunna tolka och identifiera negationer för att sentimentanalysen ska bli korrekt.

I många fall av SA analyseras texter som är skrivna på ett specifikt språk, exempelvis när nyhetsartiklar utgivna av en viss tidning analyseras. Vid TSA är det inte lika enkelt eftersom twitterinlägg kan vara skrivna på flera olika språk och det är inte ovanligt att språk blandas i inlägg. Den här studien kommer enbart analysera twitterinlägg skrivna på engelska och inhämtade inlägg skrivna på annat språk kommer filtreras bort. 

Vid TSA filtreras vanligtvis stoppord bort för att öka prestandan. Stoppord är ord som är vanligt förekommande i texter men som saknar någon större betydelse för texten ifråga. I engelskan är “the”, “is” och “who” exempel på stoppord.

Twitterinlägg behöver inte enbart innehålla text utan de kan även innehålla bilder och videor. Bilder och videor kan ge värdefull information om vad för sentiment som uttrycks i ett twitterinlägg. Det kan exempelvis ge information om vem som uttrycker en åsikt eller om vem en åsikt riktas mot. Den här studien kommer inte att ta hänsyn till mediaobjekt utan kommer enbart att analysera text. Främst på grund av att det i dagsläget är ett outforskat område.

\subsection{Problem} \label{TSAprob}
I \cite{TSAsurvey} listar författarna de problem med TSA som de anser bör utforskas ytterligare. Ett av de viktigaste problemen med TSA anser de vara bristen på datamängder som kan användas som riktmärken vid utvärdering av olika klassificeringsmodeller. Forskning som bedrivs i ämnet använder sig av olika datamängder. Dessutom är det vanligt att forskare själva samlar in och skapar egna datamängder som inte publiceras. Olika datamängder kan generera olika resultat. Därför är det svårt att jämföra olika klassificeringstekniker när det används flertalet olika datamängder. I experimentet, som presenteras i den här studien, har problemet adresserats genom att utvärderingen görs mot två kända och publika datamängder. Delvis för att kunna jämföra hur de olika klassificeringsmodellerna presterar mot olika typer av datamängder, men även för att kunna jämföra resultatet mot andra liknande utvärderingar.
\begin{table}
\centering
\caption{Förvirringsmatris}
\label{tab:fm}
	\begin{tabular}{ccc}
	\toprule
	 & \textbf{Förustspådd positiv} & \textbf{Förutspådd negativ} \\
	\midrule
	\textbf{Positiv} & Sann positiv & Falsk negativ \\
	\textbf{Negativ} & Falsk positv & Sann negativ \\
	\bottomrule
\end{tabular}
\end{table}

\section{Utvärdering} \label{TSAev}
I tabell \ref{tab:fm} ser vi en så kallad förvirringsmatris (FM) som utvärderar en klassificeringsmodell från datamängden där “positivt” eller “negativt” är förbestämt. Matrisen visar antalet sann positiv (SP), sann negativ (SN), falsk positiv (FP) och falsk negativ(FN) \cite{wiki:003}. Med dessa värden kan vi jämföra och analysera modellerna m.h.a följande utvärderingsmetoder: noggrannhet (n) \cite{wiki:011}, precision (p),  återkallelse (å) \cite{wiki:002} och F-Score \cite{wiki:001}.

\begin{labeling}{metrics}
\item [Noggrannhet] Är modellens förmåga att kunna märka ett twitterinlägg korrekt som antingen positivt eller negativt. Detta görs genom att ta summan av sannmärkta tweets delat på summan av alla märkningar.  
\item [Precision]  Är förmågan att modellen inte märker ett tweet som positivt när det är negativt. Detta görs genom att ta antalet sann positiva delat på totalt antal positivt märkta tweets. 
\item [Återkallelse] Är förmågan att modellen märker positiva tweets korrekt. Detta görs genom att ta antalet sann positiva delat på summan av antalet sann positiva och falsk negativa.
\item [F-Score] Även kallat det harmoniska medelvärdet mellan precision och återkallelse används då inte alltid precision och återkallelse räcker till för att göra en helhetsbedömning. 
\end{labeling}

I figur \ref{fig:utv} illustreras hur utvärderingmetoderna hänger ihop.

\begin{figure}[h]
\includegraphics[width=10cm]{utvardering}
\centering
\caption{Utvärderingsmetoder för TSA.}
\label{fig:utv}
\end{figure}


\section{Sammanfattning} \label{BACKsum}
I detta kapitel har bakgrunden till projektet diskuterats och där nyttan av SA och TSA har tagits upp. Intressant för uppdragsgivaren är hur de kan integrera SA och TSA i sina produkter t.ex. chatbotar och trendanalys. 

Detta kapitel ger även en överblick av vad maskininlärning är och hur maskininlärningens viktigaste komponenter hänger ihop samt hur maskininlärning kan appliceras på SA och TSA. Dessutom beskrivs de problem och utmaningar som existerar inom TSA. 

\chapter{Experiment}
\section{Intro}
I kapitlet kommer experimentet för studien att presenteras, hur det har utförts och hur de olika delarna har implementeras. Delarna utgörs av bearbetning av datamängderna, vilka särdragsurval som kommer utföras och en fördjupning i hur maskininlärningsalgoritmerna fungerar. Implementationen kommer ske i tre steg där först en lexikonbaserad modell kommer tas fram för att ge ett basfall för respektive datamängd. För att sedan implementera algoritmerna med standardparametrar och slutligen testa och justera algoritmernas parametrar. Detta för att eventuellt uppnå en förbättrad klassificeringsmodell för respektive datamängd. 
De slutgiltliga klassificeringsmodellerna kommer att diskuteras och jämföras i avsnitt \ref{res}.
\section{Bearbetning av datamängd} \label{exp:pre}
En viktig del inom SA är bearbetningen av den data som ska analyseras. Som nämndes i \ref{TSAchall}, innehåller twitterinlägg stora mängder brus på grund av det informella språket som används på Twitter, dvs data som inte är användbar för analysprocessen. Kvaliteten på datan som ska analyseras är avgörande för vilka resultat som kan uppnås vid maskininlärningen \cite{effrosynidis2017comparison}. Därför behöver data som ska analyseras bearbetas innan maskininlärningen, vilket betyder att data normaliseras och rensas på brus. Exempelvis kan det bestå av att termer som inte är nödvändiga tas bort, ersätts eller slås samman med andra. 

Det existerar flertalet olika tekniker som kan användas vid bearbetningen av data.  I \cite{effrosynidis2017comparison} utvärderas 15 av dessa bearbetningstekniker. Teknikerna utvärderas var för sig och testas mot två olika datamängder, där de för varje datamängd testas med tre olika maskininlärningsalgoritmer. Vid utvärderingen av bearbetningsteknikerna studeras noggrannheten vid sentimentklassificeringen samt antalet särdrag som genereras för varje bearbetningsteknik. Ur resultaten konstaterar författarna att det inte existerar någon direkt koppling mellan noggrannheten för klassificeringsmodellerna och antalet genererade särdrag. Författarna sammanställer resultaten från utvärderingen och kategoriserar de olika bearbetningsteknikerna i fem olika kategorier efter noggrannhet. Några bearbetningstekniker ger bättre noggrannhet för båda datamängderna, andra sämre och resultaten varierar för några. Resultaten varierar inte enbart mellan datamängderna utan de varierar även mellan klassificeringsmodellerna. 

De bearbetningstekniker som resulterar i hög noggrannhet för alla klassificeringsmodeller och de båda datamängderna är: borttagning av nummer, omvandling av ord till deras ursprungliga form samt ersättning av upprepade skiljetecken. Hantering av negationer, lemmatisering samt ersättning av URL:er och “mentions” av användare påvisar också bra resultat för båda datamängderna men dock inte för alla klassificeringsmodeller. Det som saknas i \cite{effrosynidis2017comparison} är hur de olika förbehandlingsteknikerna presterar i kombination med varandra. 

\cite{7862202} undersöker också effekten av bearbetningstekniker vid TSA. Men istället för att utvärdera varje teknik isolerat från varandra, utvärderas de istället utifrån hur de presterar i kombination med andra. Författarna har valt att fokusera på sex olika bearbetningstekniker: ersättning av negationer, expandering av förkortningar, avlägsning av nummer, avlägsning av stoppord, ersättning av förlängda ord och ersättning (borttagning) av URL:er. Bearbetningsteknikerna har utvärderats utefter hur de presterar på två olika klassificeringsuppgifter: binär och tre-vägs klassificering. Där teknikerna testas med fyra klassificeringsmodeller på fem olika datamängder. 

Vid bedömningen av prestandan vid sentimentklassificeringen har ett basfall använts. Basfallet har använt samtliga sex bearbetningstekniker för bearbetningen av datan vid testningen. När en specifik teknik har utvärderats, har tekniken i fråga exkluderats från mängden av bearbetningstekniker. Därefter har testerna repeteras, med fem bearbetningstekniker istället för sex. Sedan har förändringen av resultatet gentemot basfallet använts för att bedöma hur tekniken påverkar prestandan vid sentimentklassificeringen. Vid utvärderingen av prestandan har noggrannhet och F-score använts som mätvärden. 

Resultaten visar att ersättning av negationer och expandering av förkortningar kan ha positiv påverkan på noggrannheten vid klassificeringen. Avlägsning av URL:er, nummer och stoppord påverkar resultaten för klassificeringen minimalt, men är effektiva för att minska brus. 

Utifrån resultaten som har presenterats i \cite{effrosynidis2017comparison} och \cite{7862202} har bearbetningsteknikerna för experimentet i den här studien valts. 
Det svåra med att välja bearbetningstekniker, utifrån litteraturen, är att det kan existera flera olika varianter av en viss teknik. I \cite{effrosynidis2017comparison} hanterar de exempelvis URL:er genom att ersätta varje URL med etiketten “URL”, medan de avlägsnas i \cite{7862202}. Eftersom bearbetningsteknikerna uteslutande kommer att användas i kombination med varandra vid det här experimentet har störst vikt lagts på de tekniker som presenteras i \cite{7862202}.

\begin{figure}[H]
\includegraphics[width=12cm]{dataset}
\centering
\caption{Bearbetningstekniker som används för att bearbeta data vid experimentet.}
\label{fig:dataset}
\end{figure}

Nedan presenteras och beskrivs de bearbetningstekniker som har valts att användas för experimentet.

\begin{labeling}{preproc}
\item [Avlägsna siffror] 
Siffror tas bort från ett twitterinläggen.
\item [Avlägsna stoppord] 
Stoppord, som beskrevs i \ref{TSAchall}, tas bort från inläggen genom att twitterinläggen söks igenom på stoppord från en fördefinierad lista. 
\item[Avlägsna URL:er]
URL:er tas bort från twitterinlägg.
\item[Ersätta negationer]
I \ref{TSAchall} diskuterades vikten av att kunna tolka och identifiera negationer för att SA ska bli korrekt. I engelskan är sammandragsförkortningar vanligt förekommande. Termen “don’t” är exempel på en sammandragsförkortningen för “do not” . För experimentet har sammandragsförkortningarna “n’t”, “can’t” och “won’t” omvandlas till “not”, “can not” och “will not”, utefter hur metoden beskrevs i \cite{7862202}.
\item[Omvandla versaler till gemener]
Alla versaler omvandlas till gemener, dvs texterna som analyseras består enbart av gemener. Det gör att ord som är skrivna på flera olika sätt slås samman till ett \cite{effrosynidis2017comparison}. Vokabuläret blir då mindre, vilket gör att storleken på problemet minskas.  
\item[Avlägsna skiljetecken]
Skiljetecken tas bort från twitterinlägg.
\item[Avlägsna “hashtags”]
“Hashtags” tas bort från inläggen som ska analyseras.
\item[Avlägsna “mentions”]
“Mentions” av twitteranvändare tas bort.
\item[Avlägsna repeterande mellanslag]
Om två eller fler mellanslag förekommer efter varandra omvandlas de till ett mellanslag.
\item[Avlägsna accenter]
Accenter tas bort från bokstäver. 
\item[Avlägsna HTML-kod]
Om HTML-kod förekommer i ett inlägg tas det bort.
\end{labeling}

\section{Särdragsurval} \label{exp:feat}
Inom maskininlärning definieras ett särdrag som en individuell mätbar egenskap eller kännetecken på ett fenomen som har observerats, begreppet särdrag kommer från variabler som används inom statistik. Att välja korrekt, informativa och oberoende särdrag är ett kritiskt moment för att maskininlärningsalgoritmen ska kunna uppnå sin fulla potential och undvika fel klassificeringar \cite{wiki:014}. 
I \cite{TSAsurvey} presenteras det fyra olika särdrags klasser inom TSA: semantisk, syntaktisk, stilistisk och twitter-specifika särdrag.

\begin{figure}[H]
\includegraphics[width=9cm]{grams}
\centering
\caption{Illustrerar n-grams på en mening.}
\label{fig:grams}
\end{figure}

\begin{labeling}{preproc}
\item [Semantisk särdrag]
Används mestadels för att ta ut  åsikts ord, sentiment ord och negationer. Åsikts ord är ord eller meningar som kan innehålla någon typ av åsikt medans sentiment ord är ord som innehåller något positivt eller negativt. Negationer är viktigt koncept eftersom en mening som innehåller någon typ av negation kan skifta om twitterinlägget är positivt eller negativt. Studien kommer använda sentiment ord i lexikon implementationen \ref{impl:lex} och negationer som även diskuterats i \ref{exp:pre} kommer implementeras i \ref{impl:pre}.

\item [Syntaktisk särdrag]
Används för att utforska påverkan av olika termer i SA och TSA, syntaktiska särdrag bryts ner till unigram, bigram, trigrams, n-grams, termfrekvens och “Part of Speech” (POS). Där n-grams är ett samlingsord för uni-, bi- och trigram, i figur \ref{fig:grams} illustreras hur n-grams modellen fungerar på en enkel mening och hur meningens ord grupperas på olika sätta till ett ord eller fras. **ta upp något om varför det används?**

Termfrekvens används i kombination med n-grams eftersom längre twitterinlägg kan ha ett genomsnittligt högre antal förekomster av ett ord än ett kortare twitterinlägg. Genom att dela antalet förekomster av ett ord i ett twitterinlägg med alla ord som finns i twitterinlägget kan detta undvikas \cite{scikit:001}.

POS utförs genom att man räknar hur många substantiv, verb och adjektiv som existerar i ett twitterinlägg. POS kan t.ex användas för att ta redan på åsikter i ett twitterinlägg där antalet adjektiv kan relateras till vilken åsikt ett twitterinlägget har.

Studien kommer implementera n-grams och termfrekvens för varje klassificeringsalgoritm i \ref{impl}. POS kommer inte implementeras i studien då \cite{go2009twitter}, \cite{feature:001} rapporterar försämrad precision. Däremot rapporterar \cite{feature:002} små förbättringar vid användning av POS.
\item [Stilistisk särdrag]
Är särdrag som kommer från det informella skrivsättet som används på Twitter där t.ex emojis, förkortningar, slang och skiljetecken används. Enligt \cite{feature:002} kan emojis ha en stor betydelse för TSA. Men eftersom STS datamängden har avlägsnat emojis, då “distant supervision” \cite{sts:001} har använts, kommer inte studiens modeller ta hänsyn till emojis. Därför har även emojis från SemEval datamängden filtreras bort i \ref{exp:pre}. Studien kommer inte hantera slang eftersom inget större slanglexikon var öppet för användning. 
Förkortningar och skiljetecken kommer hanteras i denna studien och har diskuterats i \ref{exp:pre} och implementeras i \ref{impl:pre}
\item [Twitter-specifika särdrag] 
Är särdrag som är specifika för Twitters domän som t.ex “hashtags” och “mentions” vilket diskuteras i \ref{TSA} och \ref{exp:pre}.
\end{labeling}




\section{Algoritmer}
** Skall det skrivas något kort intro här?***
\subsection{Naive Bayes}
I \ref{MLnb} beskrivs det att Naive Bayes algoritmen är baserad på Bayes theorem  \cite{wiki:009} vilket för TSA betyder att räkna ut sannolikheten om ett twitterinlägg $B$ är positivt $A$ eller negativt $\neg A$. 
\begin{equation}\label{eq:btpos}
p(A|B) = \frac{p(B|A) * p(A)}{P(B)}
\end{equation}
\begin{equation}\label{eq:bt}
p(!A|B) = \frac{p(B|\neg A) * p(!A)}{P(B)}
\end{equation}

Som nämns ovan är TSA ett binärt klassificeringsproblem d.v.s om  $B$ är $A$ eller $\neg A$ . Därför delas ekvation \ref{eq:btpos} med ekvation \ref{eq:bt} vilket ger oss $\hat{P} > 1 = A$ och om $\hat{P} < 1 = \neg A$.  

\begin{equation}\label{eq:phat}
\hat{P} = \frac{p(B|A) * p(A)}{p(B|\neg A) * p(\neg A)}
\end{equation}

För att ekvation \ref{eq:phat} skall vara “Naive” antar vi att varje ord $b_w$ i $B$ är oberoende av varandra vilket betyder att vi inte längre klassificerar $B$ utan $b_w$, $P(B) = P(b_{w1}) * P(b_{w2}) * … * P(b_{wn})$ där $n$ är antalet ord i $B$.

För att beräkna sannolikheten att $b_w$ är $A$ eller $\neg A$ används en Dirichlet prior \cite{wiki:012}\cite{nb:007} som ger oss en enkel formel för att räkna ut sannolikheten. Där $N_{ci}$ är antalet gånger ordet $w_b$ förekommer i $A's$ eller $\neg A's$ datamängd, delat med antalet ord i $A$ eller $\neg A$ $(N_c)$. Ett problem som uppstår är när $N_{ci} = 0$ d.v.s när ordet $w_b$ saknas i datamängden. För att motverka detta används så kallad additiv utjämning \cite{wiki:013}, där $\alpha_i$ sätts till 1 och $\alpha$ betecknar antal ord i datamängden. 

\begin{equation}
P(A | w_b)= \frac{N_{ci} + \alpha_i}{N_c + \alpha}
\end{equation}

*** Exemple där vi visar att ett tweet är positivt med uträkningar ***

\subsection{Support Vector Machine}
SVM algoritmen skapar en modell utifrån en given mängd märkt träningsdata \cite{svm:002}. 
Modellen som skapas har sedan förmågan att kategorisera ny indata i en av de två kategorierna. 

Den skapade SVM-modellen representerar träningsdata som punkter i ett koordinatsystem. I koordinatsystemet kartläggs data så att de två kategorierna är tydligt separerade med ett så stort mellanrum som möjligt. När modellen kategoriserar ny indata kartläggs den datan till samma koordinatsystem, för att sedan kategoriseras utefter vilken sida av mellanrummet den hamnar på.

\begin{figure}[H]
\includegraphics[width=9cm]{linearsvm_hpwithmargins}
\centering
\caption{.}
\label{fig:svmmarg}
\end{figure}  

För att separera kategorierna konstruerar SVM ett hyperplan. I figur \ref{fig:svmmarg} representeras hyperplanet av linjen mellan kategorierna. Datapunkterna som ligger närmast hyperplanet för respektive kategori kallas för stödvektorer och de är utefter de punkterna som hyperplanet positioneras \cite{svm:003}. Det kan finnas flera möjliga hyperplan som kan kategorisera datan. Idén bakom SVM är att hitta hyperplanet som bäst delar upp datamängden i två kategorier. Ju större marginal mellan kategorierna desto mindre känslig blir modellen för generaliseringsfel \cite{svm:002}. Därför anses hyperplanet som har störst marginal till de närmaste stödvektorerna från respektive kategori ge en bra separation av data.

\begin{figure}[H]
\includegraphics[width=9cm]{nonlinearsvm}
\centering
\caption{.}
\label{fig:svmnonl}
\end{figure} 

Figur \ref{fig:svmnonl} visar ett exempel på två kategorier av data som inte går att separera linjärt. I fall som dessa ritas datapunkterna om i en högre dimension för att en separation ska bli möjlig \cite{svm:003}, vilket illustreras i figur X.X. Processen upprepas tills dess att ett hyperplan kan separera datan. Metoden SVM använder för att utföra detta effektivt kallas “kernel trick” \cite{svm:004}.  

Eftersom att antalet särdrag som genereras vid klassificering av text är så pass högt, resulterar det i att en icke-linjär klassificerare överanpassar data \cite{svm:005}. Därför har en linjär klassificerare valts att användas vid den här studien.
(*** linjär vs. icke-linjär??? ***)



\section{Implementation}\label{impl}
\section{Databearbetning}\label{impl:pre}
\subsection{Lexikon}\label{impl:lex}
\subsection{Naive Bayes}\label{impl:nb}
\subsection{Support Vector Machine}\label{impl:svm}
\subsection{Prediction program.}
\subsection{* ev GUI implementation om tid finns *}
\section{Sammanfattning}

\chapter{Resultat} \label{res}
\section{Intro}
\section{Resultatet mellan modellerna}
\subsection{Dataset 1 -> jämför resultat mellan modellerna}
\subsection{Dataset 2 -> jämför resultat mellan modellerna}
\subsection{Dataset 3 -> jämför resultat mellan modellerna}
\newpage
\section{Implementations mässigt vilken modell är lättast?}
\section{implementations jämförelse (resultat VS förväntat)}
\section{Summering}

\chapter{Slutsats}
\section{Sammanfattning}
\section{Problem}
\section{Begränsningar}
\newpage
\section{Vidare utveckling}
\section{Slutord}



\bibliographystyle{unsrtnat} 
\bibliography{../refs/thesisref}


\restoregeometry%

\end{document}
\endinput
%%
%% End of file `kaumasterstemplate.tex'.
